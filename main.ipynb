{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb072e1",
   "metadata": {},
   "source": [
    "# Projeto Aplicado III - Construindo um sistema de recomenda√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c42892",
   "metadata": {},
   "source": [
    "O projeto tem como objetivo **desenvolver um sistema de recomenda√ß√£o de filmes** utilizando o *5000 Movie Dataset*, dispon√≠vel no Kaggle, que re√∫ne informa√ß√µes detalhadas sobre cerca de 5.000 produ√ß√µes do The Movie Database (TMDb). Esse conjunto de dados inclui vari√°veis como **or√ßamento, g√™neros, popularidade, empresas produtoras, pa√≠ses de produ√ß√£o, elenco e equipe t√©cnica**, permitindo a aplica√ß√£o de t√©cnicas de aprendizado de m√°quina para sugerir conte√∫dos mais relevantes aos usu√°rios.\n",
    "\n",
    "A iniciativa busca n√£o apenas aprimorar compet√™ncias pr√°ticas em **ci√™ncia de dados e minera√ß√£o de dados**, mas tamb√©m contribuir para os **Objetivos de Desenvolvimento Sustent√°vel (ODS)** da ONU, como o **ODS 9 (Inova√ß√£o e Infraestrutura)**, o **ODS 4 (Educa√ß√£o de Qualidade)** e o **ODS 10 (Redu√ß√£o das Desigualdades)**. Assim, o sistema pretende oferecer recomenda√ß√µes personalizadas que promovam maior **diversidade cultural e inclus√£o digital**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed057d11",
   "metadata": {},
   "source": [
    "Para a an√°lise e desenvolvimento deste projeto, ser√° necess√°rio utilizar um conjunto de bibliotecas do ecossistema Python, cada uma com um papel espec√≠fico no fluxo de trabalho de **an√°lise explorat√≥ria** e **constru√ß√£o do sistema de recomenda√ß√£o**.\n",
    "\n",
    "- **pandas**: essencial para manipula√ß√£o e an√°lise de dados tabulares, permitindo leitura, limpeza e transforma√ß√£o dos datasets `tmdb_5000_movies` e `tmdb_5000_credits`.  \n",
    "- **numpy**: fornece suporte para opera√ß√µes matem√°ticas e vetoriza√ß√£o, aumentando a efici√™ncia no processamento de dados.  \n",
    "- **matplotlib**: utilizada para criar visualiza√ß√µes b√°sicas, como gr√°ficos de barras, dispers√£o e histogramas.  \n",
    "- **seaborn**: complementa o matplotlib oferecendo visualiza√ß√µes estat√≠sticas mais sofisticadas e com est√©tica aprimorada.  \n",
    "- **scikit-learn**: importante para o pr√©-processamento dos dados, c√°lculo de m√©tricas de avalia√ß√£o e implementa√ß√£o de algoritmos de recomenda√ß√£o baseados em aprendizado de m√°quina.  \n",
    "- **scipy**: ser√° usada para c√°lculos matem√°ticos \n",
    "- **surprise (scikit-surprise)**: biblioteca especializada em sistemas de recomenda√ß√£o, especialmente nos modelos colaborativos como **SVD** e **KNNBasic**, permitindo comparar t√©cnicas.  \n",
    "- **lightfm**: possibilita a constru√ß√£o de sistemas de recomenda√ß√£o h√≠bridos, combinando informa√ß√µes de conte√∫do e intera√ß√µes de usu√°rios.  \n",
    "- **tensorflow / pytorch**: √∫teis caso seja necess√°rio evoluir para modelos de recomenda√ß√£o mais avan√ßados baseados em **deep learning**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f5ca1",
   "metadata": {},
   "source": [
    "Abaixo, ser√° realizada a importa√ß√£o das bibliotecas necess√°rias para a **an√°lise explorat√≥ria** e a **constru√ß√£o do sistema de recomenda√ß√£o**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07836b9a",
   "metadata": {},
   "source": [
    "Antes de iniciar a an√°lise, √© necess√°rio garantir que todas as bibliotecas utilizadas neste projeto estejam instaladas no ambiente.  \n",
    "Para isso, basta executar o comando abaixo no terminal ou em uma c√©lula do Jupyter Notebook (prefixado com `!`):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb00113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas para an√°lise de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Bibliotecas para visualiza√ß√£o\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas para sistemas de recomenda√ß√£o\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import scipy\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic\n",
    "from lightfm import LightFM\n",
    "\n",
    "# Deep Learning (opcional, dependendo da abordagem)\n",
    "import tensorflow as tf\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc0598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos datasets\n",
    "movies_df = pd.read_csv(\"datasets/tmdb_5000_movies.csv\")\n",
    "credits_df = pd.read_csv(\"datasets/tmdb_5000_credits.csv\")\n",
    "\n",
    "# Mostrando as primeiras linhas dos datasets\n",
    "print(\"üìå Movies Dataset:\")\n",
    "display(movies_df.head())\n",
    "\n",
    "print(\"\\nüìå Credits Dataset:\")\n",
    "display(credits_df.head())\n",
    "\n",
    "# Informa√ß√µes b√°sicas dos datasets\n",
    "print(\"\\nüîé Informa√ß√µes do Movies Dataset:\")\n",
    "print(movies_df.info())\n",
    "\n",
    "print(\"\\nüîé Informa√ß√µes do Credits Dataset:\")\n",
    "print(credits_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40fd2f4",
   "metadata": {},
   "source": [
    "Nesta etapa, ser√° realizada a **sele√ß√£o das colunas relevantes** para a constru√ß√£o do sistema de recomenda√ß√£o.  \n",
    "\n",
    "O objetivo √© reduzir o dataframe apenas √†s vari√°veis que realmente ser√£o utilizadas no modelo, garantindo maior **efici√™ncia no processamento**, evitando redund√¢ncias e mantendo o foco nos atributos mais informativos para a gera√ß√£o das recomenda√ß√µes.\n",
    "\n",
    "Al√©m disso, tamb√©m ser√£o tratados os valores nulos para diminuir o ru√≠do presente no dataset.\n",
    "\n",
    "Tamb√©m ser√° feito um **merge com o dataframe de cr√©ditos**, permitindo integrar informa√ß√µes sobre elenco e equipe t√©cnica ao conjunto de dados principal, enriquecendo assim a base para a constru√ß√£o do sistema de recomenda√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies Dataset\n",
    "\n",
    "# Filtrando somente linhas em que o filme est√° com status 'Released'\n",
    "# Utilizamos o reset_index(drop=True) para resetar os √≠ndices do DataFrame ap√≥s o filtro\n",
    "movies_df = movies_df[movies_df['status'] == 'Released'].reset_index(drop=True)\n",
    "# Agora, filtraremos apenas as colunas que nos interessam para a an√°lise\n",
    "movies_df = movies_df[['id', 'title', 'genres', 'vote_average', 'vote_count', 'popularity', 'release_date', 'overview', 'runtime', 'keywords', 'production_companies', 'production_countries', 'spoken_languages']]\n",
    "# Tratando linhas com valores nulos\n",
    "movies_df = movies_df.dropna().reset_index(drop=True)\n",
    "# Convertendo a coluna 'release_date' para o tipo datetime\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df['release_date'], errors='coerce')\n",
    "\n",
    "# Credits Dataset\n",
    "# Selecionando apenas as colunas que nos interessam\n",
    "credits_df = credits_df[['movie_id', 'cast', 'crew']]\n",
    "# Tratando linhas com valores nulos\n",
    "credits_df = credits_df.dropna().reset_index(drop=True)\n",
    "# Renomeando a coluna 'movie_id' para 'id' para facilitar o merge\n",
    "credits_df = credits_df.rename(columns={'movie_id': 'id'})\n",
    "\n",
    "# Merge dos datasets\n",
    "# Realizando o merge dos datasets 'movies_df' e 'credits_df' com base na coluna 'id'\n",
    "movies_df = movies_df.merge(credits_df, on='id')\n",
    "# Mostrando as primeiras linhas do dataset final\n",
    "print(\"\\nüìå Dataset Final ap√≥s Merge:\")\n",
    "display(movies_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc8c38",
   "metadata": {},
   "source": [
    "Neste trecho de c√≥digo √© realizado o **tratamento das colunas no formato JSON** presentes nos datasets.  \n",
    "Foram criadas fun√ß√µes auxiliares para converter as colunas que armazenam listas de dicion√°rios em **listas de valores extra√≠dos**, de forma a facilitar a manipula√ß√£o e an√°lise.  \n",
    "\n",
    "- A fun√ß√£o `parse_json_column` √© respons√°vel por percorrer colunas no formato JSON e **extrair os valores de um campo espec√≠fico** (como `name`, `iso_3166_1` ou `iso_639_1`).  \n",
    "- A fun√ß√£o `extract_director` percorre a coluna `crew` e **identifica o diretor principal** de cada filme, criando uma nova coluna `director`.  \n",
    "\n",
    "Ap√≥s o processamento, as colunas originais em JSON s√£o transformadas em listas de valores mais simples, e a coluna `crew` foi descartada, visto que sua informa√ß√£o relevante (o diretor) j√° foi extra√≠da.  \n",
    "Esse tratamento torna o dataframe mais **limpo e estruturado**, possibilitando seu uso na an√°lise explorat√≥ria e na constru√ß√£o do sistema de recomenda√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954745df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√µes para processar as colunas JSON\n",
    "def parse_json_column(df, column_name, key='name'):\n",
    "    def extract_names(json_str):\n",
    "        if isinstance(json_str, str):\n",
    "            try:\n",
    "                list_of_dicts = ast.literal_eval(json_str)\n",
    "                if isinstance(list_of_dicts, list):\n",
    "                    return [d[key] for d in list_of_dicts if key in d]\n",
    "            except (ValueError, SyntaxError):\n",
    "                pass\n",
    "        return []\n",
    "    df[column_name] = df[column_name].apply(extract_names)\n",
    "    return df\n",
    "\n",
    "# M√©todo para extrair o diretor do elenco\n",
    "def extract_director(crew_json):\n",
    "    if isinstance(crew_json, str):\n",
    "        try:\n",
    "            crew_list = ast.literal_eval(crew_json)\n",
    "            for member in crew_list:\n",
    "                if member.get('job') == 'Director':\n",
    "                    return member.get('name')\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass\n",
    "    return np.nan\n",
    "\n",
    "# Aplicando as fun√ß√µes para explodir as colunas JSON\n",
    "movies_df = parse_json_column(movies_df, 'genres')\n",
    "movies_df = parse_json_column(movies_df, 'keywords')\n",
    "movies_df = parse_json_column(movies_df, 'production_companies')\n",
    "movies_df = parse_json_column(movies_df, 'production_countries', key='iso_3166_1') \n",
    "movies_df = parse_json_column(movies_df, 'spoken_languages', key='iso_639_1')\n",
    "movies_df = parse_json_column(movies_df, 'cast', key='name')\n",
    "movies_df['director'] = movies_df['crew'].apply(extract_director)\n",
    "\n",
    "# Removendo a coluna 'crew' original, pois j√° extra√≠mos o diretor\n",
    "movies_df = movies_df.drop(columns=['crew'])\n",
    "\n",
    "# Mostrando as primeiras linhas do dataset ap√≥s o tratamento das colunas JSON\n",
    "print(\"\\nüìå Dataset Final ap√≥s tratamento de JSON:\")\n",
    "display(movies_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
